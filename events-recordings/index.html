<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="2023-01-26: Trevor Bekolay, Nengo - Applied Brain Research Recording https://youtu.be/sgu9l_bqAHM
Slides click here
Speaker&amp;rsquo;s bio Trevor Bekolay’s primary research interest is in learning and memory. In his Master’s degree, he explored how to do supervised, unsupervised, and reinforcement learning in networks of biologically plausible spiking neurons. In his PhD, he applied this knowledge to the domain of speech to explore how sounds coming into the ear become high-level linguistic representations, and how those representations become sequences of vocal tract movements that produce speech."><title>Events recordings</title><link rel=canonical href=https://open-neuromorphic.org/events-recordings/><link rel=stylesheet href=/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css><meta property="og:title" content="Events recordings"><meta property="og:description" content="2023-01-26: Trevor Bekolay, Nengo - Applied Brain Research Recording https://youtu.be/sgu9l_bqAHM
Slides click here
Speaker&amp;rsquo;s bio Trevor Bekolay’s primary research interest is in learning and memory. In his Master’s degree, he explored how to do supervised, unsupervised, and reinforcement learning in networks of biologically plausible spiking neurons. In his PhD, he applied this knowledge to the domain of speech to explore how sounds coming into the ear become high-level linguistic representations, and how those representations become sequences of vocal tract movements that produce speech."><meta property="og:url" content="https://open-neuromorphic.org/events-recordings/"><meta property="og:site_name" content="Open Neuromorphic"><meta property="og:type" content="article"><meta property="article:section" content="Page"><meta name=twitter:title content="Events recordings"><meta name=twitter:description content="2023-01-26: Trevor Bekolay, Nengo - Applied Brain Research Recording https://youtu.be/sgu9l_bqAHM
Slides click here
Speaker&amp;rsquo;s bio Trevor Bekolay’s primary research interest is in learning and memory. In his Master’s degree, he explored how to do supervised, unsupervised, and reinforcement learning in networks of biologically plausible spiking neurons. In his PhD, he applied this knowledge to the domain of speech to explore how sounds coming into the ear become high-level linguistic representations, and how those representations become sequences of vocal tract movements that produce speech."><link rel="shortcut icon" href=/img/ONM-logo.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/ONM-logo.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Open Neuromorphic</a></h1><h2 class=site-description>We are an organization of neuromorphic open source enthusiasts! We build tools for the community, host talks and discuss research. Click the Discord item below to join us and jump right in!</h2></div></header><ol class=social-menu><li><a href=https://discord.gg/C9bzWgNmqk target=_blank title=Discord rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-discord" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="9" cy="12" r="1"/><circle cx="15" cy="12" r="1"/><path d="M7.5 7.5c3.5-1 5.5-1 9 0"/><path d="M7 16.5c3.5 1 6.5 1 10 0"/><path d="M15.5 17c0 1 1.5 3 2 3 1.5.0 2.833-1.667 3.5-3 .667-1.667.5-5.833-1.5-11.5-1.457-1.015-3-1.34-4.5-1.5l-1 2.5"/><path d="M8.5 17c0 1-1.356 3-1.832 3-1.429.0-2.698-1.667-3.333-3-.635-1.667-.476-5.833 1.428-11.5C6.151 4.485 7.545 4.16 9 4l1 2.5"/></svg></a></li><li><a href=https://github.com/open-neuromorphic target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/groups/9267873 target=_blank title=LinkedIn rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-linkedin" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="4" width="16" height="16" rx="2"/><line x1="8" y1="11" x2="8" y2="16"/><line x1="8" y1="8" x2="8" y2="8.01"/><line x1="12" y1="16" x2="12" y2="11"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li><li><a href=https://www.youtube.com/@openneuromorphic target=_blank title=YouTube rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-youtube" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="4"/><path d="M10 9l5 3-5 3z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/events/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-event" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="5" width="16" height="16" rx="2"/><line x1="16" y1="3" x2="16" y2="7"/><line x1="8" y1="3" x2="8" y2="7"/><line x1="4" y1="11" x2="20" y2="11"/><rect x="8" y="15" width="2" height="2"/></svg><span>Events</span></a></li><li class=current><a href=/events-recordings/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-youtube" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#2c3e50" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="4"/><path d="M10 9l5 3-5 3z"/></svg><span>Events recordings</span></a></li><li><a href=/resources/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-code" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="7 8 3 12 7 16"/><polyline points="17 8 21 12 17 16"/><line x1="14" y1="4" x2="10" y2="20"/></svg><span>Resources</span></a></li><li><a href=/team/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-users" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="9" cy="7" r="4"/><path d="M3 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/><path d="M16 3.13a4 4 0 010 7.75"/><path d="M21 21v-2a4 4 0 00-3-3.85"/></svg><span>Team</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-open-source" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3a9 9 0 013.618 17.243l-2.193-5.602a3 3 0 10-2.849.0l-2.193 5.603A9 9 0 0112 3z"/></svg><span>About</span></a></li><li><a href=/getting-involved/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-code" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="#9e9e9e" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="7 8 3 12 7 16"/><polyline points="17 8 21 12 17 16"/><line x1="14" y1="4" x2="10" y2="20"/></svg><span>Getting involved</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#2023-01-26-trevor-bekolay-nengo---applied-brain-research>2023-01-26: Trevor Bekolay, Nengo - Applied Brain Research</a><ol><li><a href=#recording>Recording</a></li><li><a href=#slides>Slides</a></li><li><a href=#speakers-bio>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-02-14-giorgia-dellaferrera-pepita---a-forward-forward-alternative-to-backpropagation>2023-02-14: Giorgia Dellaferrera, PEPITA - A forward-forward alternative to backpropagation</a><ol><li><a href=#recording-1>Recording</a></li><li><a href=#slides-1>Slides</a></li><li><a href=#speakers-bio-1>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-03-02-jason-eshraghian-hands-on-session-with-snntorch>2023-03-02: Jason Eshraghian, Hands-on session with snnTorch</a><ol><li><a href=#recording-2>Recording</a></li><li><a href=#notebooks>Notebooks</a></li><li><a href=#speakers-bio-2>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-03-21-catherine-schuman-evolutionary-optimization-for-neuromorphic-systems>2023-03-21: Catherine Schuman, Evolutionary Optimization for Neuromorphic Systems</a><ol><li><a href=#recording-3>Recording</a></li><li><a href=#speakers-bio-3>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-04-04-gregor-lenz-hands-on-session-with-sinabs-and-speck>2023-04-04: Gregor Lenz, Hands-on session with Sinabs and Speck</a><ol><li><a href=#recording-4>Recording</a></li><li><a href=#speakers-bio-4>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-04-26-dylan-muir-hands-on-session-with-xylo-and-rockpool>2023-04-26: Dylan Muir, Hands-on session with Xylo and Rockpool</a><ol><li><a href=#recording-5>Recording</a></li><li><a href=#code>Code</a></li><li><a href=#slides-2>Slides</a></li><li><a href=#speakers-bio-5>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-05-31-andreas-wild--mathis-richter-lava---an-open-source-software-framework-for-developing-neuro-inspired-applications>2023-05-31: Andreas Wild & Mathis Richter, Lava - an open-source software framework for developing neuro-inspired applications.</a><ol><li><a href=#recording-6>Recording</a></li><li><a href=#slides-3>Slides</a></li><li><a href=#speakers-bios>Speakers&rsquo; bios</a></li></ol></li><li><a href=#2023-06-08-federico-corradi---low-power-spiking-neural-network-processing-systems-for-extreme-edge-applications>2023-06-08: Federico Corradi - Low-power spiking neural network processing systems for extreme-edge applications</a><ol><li><a href=#recording-7>Recording</a></li><li><a href=#speakers-bio-6>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-07-11-konrad-kording-does-the-brain-do-gradient-descent>2023-07-11: Konrad Kording, Does the brain do gradient descent?</a><ol><li><a href=#recording-8>Recording</a></li><li><a href=#speakers-bio-7>Speaker&rsquo;s bio</a></li></ol></li><li><a href=#2023-07-19-lana-josipović-from-cc-to-dynamically-scheduled-circuits>2023-07-19: Lana Josipović, From C/C++ to Dynamically Scheduled Circuits</a><ol><li><a href=#recording-9>Recording</a></li><li><a href=#speakers-bio-8>Speaker&rsquo;s bio</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><div class=article-title-wrapper><h2 class=article-title><a href=/events-recordings/>Events recordings</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>7 minute read</time></div></footer></div></header><section class=article-content><h2 id=2023-01-26-trevor-bekolay-nengo---applied-brain-research>2023-01-26: Trevor Bekolay, Nengo - Applied Brain Research</h2><p><img src=/events-recordings/trevor-bekolay.jpeg width=460 height=460 srcset="/events-recordings/trevor-bekolay_hufbec93062349485948350099f8024531_51540_480x0_resize_q75_box.jpeg 480w, /events-recordings/trevor-bekolay_hufbec93062349485948350099f8024531_51540_1024x0_resize_q75_box.jpeg 1024w" loading=lazy alt="Trevor Bekolay" class=gallery-image data-flex-grow=100 data-flex-basis=240px></p><h3 id=recording>Recording</h3><p><a class=link href=https://youtu.be/sgu9l_bqAHM target=_blank rel=noopener>https://youtu.be/sgu9l_bqAHM</a></p><h3 id=slides>Slides</h3><p><a class=link href=2023-01-26-Nengo.pdf>click here</a></p><h3 id=speakers-bio>Speaker&rsquo;s bio</h3><p>Trevor Bekolay’s primary research interest is in learning and memory. In his Master’s degree, he explored how to do supervised, unsupervised, and reinforcement learning in networks of biologically plausible spiking neurons. In his PhD, he applied this knowledge to the domain of speech to explore how sounds coming into the ear become high-level linguistic representations, and how those representations become sequences of vocal tract movements that produce speech.</p><p>Trevor is also passionate about reproducible science, particularly when complex software pipelines are involved. In 2013, he started a development effort to reimplement the Nengo neural simulator from scratch in Python, which has now grown to a project with over 20 contributors around the world.</p><h2 id=2023-02-14-giorgia-dellaferrera-pepita---a-forward-forward-alternative-to-backpropagation>2023-02-14: Giorgia Dellaferrera, PEPITA - A forward-forward alternative to backpropagation</h2><p><img src=/events-recordings/giorgia-dellaferrera.jpeg width=500 height=500 srcset="/events-recordings/giorgia-dellaferrera_hua839c980f4c66a1a65fd81ca426e703b_92518_480x0_resize_q75_box.jpeg 480w, /events-recordings/giorgia-dellaferrera_hua839c980f4c66a1a65fd81ca426e703b_92518_1024x0_resize_q75_box.jpeg 1024w" loading=lazy alt="Giorgia Dellaferrera" class=gallery-image data-flex-grow=100 data-flex-basis=240px></p><h3 id=recording-1>Recording</h3><p><a class=link href=https://youtu.be/RKgdUrCun5w target=_blank rel=noopener>https://youtu.be/RKgdUrCun5w</a></p><h3 id=slides-1>Slides</h3><p><a class=link href=2023-02-14-Giorgia-Dellaferrera.pdf>click here</a></p><h3 id=speakers-bio-1>Speaker&rsquo;s bio</h3><p>Giorgia Dellaferrera has completed her PhD in computational neuroscience at the Institute of Neuroinformatics (ETH Zurich and the University of Zurich) and IBM Research Zurich with Prof. Indiveri, Prof. Eleftheriou and Dr. Pantazi. Her doctoral thesis focused on the interplay between neuroscience and artificial intelligence, with an emphasis on learning mechanisms in brains and machines. During her PhD, she visited the lab of Prof. Kreiman at the Harvard Medical School (US), where she developed a biologically inspired training strategy for artificial neural networks. Before her PhD, Giorgia obtained a master in Applied Physics at the Swiss Federal Institute of Technology Lausanne (EPFL) and worked as an intern at the Okinawa Institute of Science and Technology, Logitech, Imperial College London, and EPFL.</p><h2 id=2023-03-02-jason-eshraghian-hands-on-session-with-snntorch>2023-03-02: Jason Eshraghian, Hands-on session with snnTorch</h2><p><img src=/events-recordings/jason-eshraghian.webp width=602 height=480 srcset="/events-recordings/jason-eshraghian_hu5d2d5366ae47912bc22f41487225bf0b_38920_480x0_resize_q75_h2_box_2.webp 480w, /events-recordings/jason-eshraghian_hu5d2d5366ae47912bc22f41487225bf0b_38920_1024x0_resize_q75_h2_box_2.webp 1024w" loading=lazy alt="Jason Eshraghian" class=gallery-image data-flex-grow=125 data-flex-basis=301px></p><h3 id=recording-2>Recording</h3><p><a class=link href=https://youtu.be/aUjWRpisRRg target=_blank rel=noopener>https://youtu.be/aUjWRpisRRg</a></p><h3 id=notebooks>Notebooks</h3><p><a class=link href=https://github.com/open-neuromorphic/hands-on-session-snntorch-230302 target=_blank rel=noopener>https://github.com/open-neuromorphic/hands-on-session-snntorch-230302</a></p><h3 id=speakers-bio-2>Speaker&rsquo;s bio</h3><p><a class=link href=https://jasoneshraghian.com target=_blank rel=noopener>Jason K. Eshraghian</a> is an Assistant Professor at the Department of Electrical and Computer Engineering at UC Santa Cruz, CA, USA. Prior to that, he was a Post-Doctoral Researcher at the Department of Electrical Engineering and Computer Science, University of Michigan in Ann Arbor. He received the Bachelor of Engineering (Electrical and Electronic) and the Bachelor of Laws degrees from The University of Western Australia, WA, Australia in 2016, where he also completed his Ph.D. Degree.</p><p>Professor Eshraghian was awarded the 2019 IEEE VLSI Best Paper Award, the Best Paper Award at 2019 IEEE Artificial Intelligence CAS Conference, and the Best Live Demonstration Award at 2020 IEEE ICECS for his work on neuromorphic vision and in-memory computing using RRAM. He currently serves as the secretary-elect of the IEEE Neural Systems and Applications Committee, and was a recipient of the Fulbright Future Fellowship (Australian-America Fulbright Commission), the Forrest Research Fellowship (Forrest Research Foundation), and the Endeavour Fellowship (Australian Government).</p><h2 id=2023-03-21-catherine-schuman-evolutionary-optimization-for-neuromorphic-systems>2023-03-21: Catherine Schuman, Evolutionary Optimization for Neuromorphic Systems</h2><p><img src=/events-recordings/catherine-schuman.webp width=444 height=614 srcset="/events-recordings/catherine-schuman_huc056e41512c17dd339d4074ee71f8169_11002_480x0_resize_q75_h2_box_2.webp 480w, /events-recordings/catherine-schuman_huc056e41512c17dd339d4074ee71f8169_11002_1024x0_resize_q75_h2_box_2.webp 1024w" loading=lazy alt="Catherine Schuman" class=gallery-image data-flex-grow=72 data-flex-basis=173px></p><h3 id=recording-3>Recording</h3><p><a class=link href=https://youtu.be/-g5XZDJPoO8 target=_blank rel=noopener>https://youtu.be/-g5XZDJPoO8</a></p><h3 id=speakers-bio-3>Speaker&rsquo;s bio</h3><p>Catherine (Katie) Schuman is an Assistant Professor in the Department of Electrical Engineering and Computer Science at the University of Tennessee (UT). She received her Ph.D. in Computer Science from UT in 2015, where she completed her dissertation on the use of evolutionary algorithms to train spiking neural networks for neuromorphic systems. Katie previously served as a research scientist at Oak Ridge National Laboratory, where her research focused on algorithms and applications of neuromorphic systems. Katie co-leads the TENNLab Neuromorphic Computing Research Group at UT. She has over 100 publications as well as seven patents in the field of neuromorphic computing. She received the Department of Energy Early Career Award in 2019.</p><h2 id=2023-04-04-gregor-lenz-hands-on-session-with-sinabs-and-speck>2023-04-04: Gregor Lenz, Hands-on session with Sinabs and Speck</h2><p><img src=/events-recordings/gregor-lenz.jpeg width=500 height=500 srcset="/events-recordings/gregor-lenz_hu401dcc7f29eb10f93ef8a57749c49e1b_50576_480x0_resize_q75_box.jpeg 480w, /events-recordings/gregor-lenz_hu401dcc7f29eb10f93ef8a57749c49e1b_50576_1024x0_resize_q75_box.jpeg 1024w" loading=lazy alt="Gregor Lenz" class=gallery-image data-flex-grow=100 data-flex-basis=240px></p><h3 id=recording-4>Recording</h3><p><a class=link href=https://youtu.be/kOiyRtvPO2Q target=_blank rel=noopener>https://youtu.be/kOiyRtvPO2Q</a></p><h3 id=speakers-bio-4>Speaker&rsquo;s bio</h3><p><a class=link href=https://lenzgregor.com target=_blank rel=noopener>Gregor Lenz</a> graduated with a Ph.D. in neuromorphic engineering from Sorbonne University. He thinks that technology can learn a thing or two from how biological systems process information.</p><p>His main interests are event cameras that are inspired by the human retina and spiking neural networks that mimic human brain in an effort to teach machines to compute a bit more like humans do. At the very least there are some power efficiency gains to be made, but hopefully more! Also he loves to build open source software for spike-based machine learning. You can find more information on his personal website.</p><p>He is the maintainer of two open source projects in the field of neuromorphic computing, <a class=link href=https://tonic.readthedocs.io target=_blank rel=noopener>Tonic</a> and <a class=link href=https://expelliarmus.readthedocs.io target=_blank rel=noopener>expelliarmus</a>.</p><h2 id=2023-04-26-dylan-muir-hands-on-session-with-xylo-and-rockpool>2023-04-26: Dylan Muir, Hands-on session with Xylo and Rockpool</h2><figure><img src="https://avatars.githubusercontent.com/u/1415148?v=4" alt="Dylan Muir" width=500px><figcaption><p>Dylan Muir</p></figcaption></figure><h3 id=recording-5>Recording</h3><p><a class=link href=https://youtu.be/WsAqVuQ3B-I target=_blank rel=noopener>https://youtu.be/WsAqVuQ3B-I</a></p><h3 id=code>Code</h3><p><a class=link href=https://github.com/synsense/OpenNeuromorphic_26042023 target=_blank rel=noopener>https://github.com/synsense/OpenNeuromorphic_26042023</a></p><h3 id=slides-2>Slides</h3><p><a class=link href=https://github.com/synsense/OpenNeuromorphic_26042023/raw/main/slides.pdf target=_blank rel=noopener>https://github.com/synsense/OpenNeuromorphic_26042023/raw/main/slides.pdf</a></p><h3 id=speakers-bio-5>Speaker&rsquo;s bio</h3><p>Dylan Muir is the Vice President for Global Research Operations; Director for Algorithms and Applications; and Director for Global Business Development at SynSense. Dr. Muir is a specialist in architectures for neural computation. He has published extensively in computational and experimental neuroscience. At SynSense he is responsible for the company research vision, and directing development of neural architectures for signal processing. Dr. Muir holds a Doctor of Science (PhD) from ETH Zurich, and undergraduate degrees (Masters) in Electronic Engineering and in Computer Science from QUT, Australia.</p><h2 id=2023-05-31-andreas-wild--mathis-richter-lava---an-open-source-software-framework-for-developing-neuro-inspired-applications>2023-05-31: Andreas Wild & Mathis Richter, Lava - an open-source software framework for developing neuro-inspired applications.</h2><figure><img src=lava-intel.png alt="The Lava framework" width='700px"'><figcaption><p>The Lava framework</p></figcaption></figure><h3 id=recording-6>Recording</h3><p><a class=link href="https://www.youtube.com/watch?v=vXZukQ6A79k" target=_blank rel=noopener>https://www.youtube.com/watch?v=vXZukQ6A79k</a></p><h3 id=slides-3>Slides</h3><p><a class=link href=lava-slides.pdf>Link</a> to slides.</p><h3 id=speakers-bios>Speakers&rsquo; bios</h3><p>Andreas Wild received the Dr. rer. nat degree in physics with a focus on the development of silicon-based electron spin qubits from the Technical University of Munich, Germany, in 2013. After joining Intel in 2013, he has been a Senior Researcher with the Intel Neuromorphic Computing Lab since 2015 where he leads algorithm research.</p><p>Mathis Richter is a Research Scientist in the Neuromorphic Computing Lab at Intel Labs, where he leads the Application Software team, developing commercial software solutions based on neuromorphic technology. Before joining Intel in 2021, he worked as a post doc and PhD student on neural process models of higher cognition at the Institute for Neural Computation, Ruhr-University Bochum.</p><h2 id=2023-06-08-federico-corradi---low-power-spiking-neural-network-processing-systems-for-extreme-edge-applications>2023-06-08: Federico Corradi - Low-power spiking neural network processing systems for extreme-edge applications</h2><figure><img src=corradi.jpg alt="Federico Corradi" width=300px><figcaption><p>Federico Corradi</p></figcaption></figure><h3 id=recording-7>Recording</h3><p><a class=link href=https://youtu.be/xiYUVzdwDIA target=_blank rel=noopener>https://youtu.be/xiYUVzdwDIA</a>.</p><h3 id=speakers-bio-6>Speaker&rsquo;s bio</h3><p>Dr. Federico Corradi is an Assistant Professor in the Electrical Engineering Department. His research activities are in Neuromorphic Computing and Engineering and span from the development of efficient models of computation to novel microelectronic architectures, with CMOS and emerging technologies, for both efficient deep learning and brain-inspired algorithms. His long-term research goal is to understand the principles of computation in natural neural systems and apply those for the development of a new generation of energy-efficient sensing and computing technologies. His research outputs find use in several application domains as robotics, machine vision, temporal signal processing, and biomedical signal analysis.</p><p>Dr. Corradi received a Ph.D. degree from the University of Zurich in Neuroinformatics and an international Ph.D. from the ETH Neuroscience Centre Zurich in 2015. He was a Postgraduate at the Institute of Neuroinformatics in 2018. From 2015 to 2018, he worked in the Institute of Neuroinformatics&rsquo; spin-off company Inilabs, developing event-based cameras and neuromorphic processors. From 2018 to 2022, he was at IMEC, the Netherlands, where he started a group focusing on neuromorphic ICs design activities. His passion for research recently brought him back to academia while keeping strong ties with startups and companies.</p><p>He is an active review editor of Frontiers in Neuromorphic Engineering, IEEE, and other international journals. In addition, he currently serves as a technical program committee member of several machine learning and neuromorphic symposiums and conferences (ICTOPEN, ICONS, DSD, EUROMICRO).</p><h2 id=2023-07-11-konrad-kording-does-the-brain-do-gradient-descent>2023-07-11: Konrad Kording, Does the brain do gradient descent?</h2><figure><img src=konrad-kording.jpg alt="Konrad Kording" width=500px><figcaption><p>Konrad Kording</p></figcaption></figure><h3 id=recording-8>Recording</h3><p><a class=link href=https://youtu.be/E5hATeCZQnU target=_blank rel=noopener>https://youtu.be/E5hATeCZQnU</a>.</p><h3 id=speakers-bio-7>Speaker&rsquo;s bio</h3><p>Konrad Kording runs his lab at the University of Pennsylvania. Konrad is interested in the question of how the brain solves the credit assignment problem and similarly how we should assign credit in the real world (through causality). In extension of this main thrust he is interested in applications of causality in biomedical research. Konrad has trained as student at ETH Zurich with Peter Konig, as postdoc at UCL London with Daniel Wolpert and at MIT with Josh Tenenbaum. After a decade at Northwestern University, he is now PIK professor at UPenn.</p><h2 id=2023-07-19-lana-josipović-from-cc-to-dynamically-scheduled-circuits>2023-07-19: Lana Josipović, From C/C++ to Dynamically Scheduled Circuits</h2><figure><img src=lana-josipovic.jpg alt="Lana Josipović" width=500px><figcaption><p>Lana Josipović</p></figcaption></figure><h3 id=recording-9>Recording</h3><p><a class=link href=https://youtu.be/mQU8iU0HyHw target=_blank rel=noopener>https://youtu.be/mQU8iU0HyHw</a>.</p><h3 id=speakers-bio-8>Speaker&rsquo;s bio</h3><p>Lana Josipović is an Assistant Professor in the Department of Information Technology and Electrical Engineering at ETH Zurich. Prior to joining ETH Zurich in January 2022, she received a Ph.D. degree in Computer Science from EPFL, Switzerland. Her research interests include reconfigurable computing and electronic design automation, with an emphasis on high-level synthesis techniques to generate hardware designs from high-level programming languages. She developed Dynamatic, an open-source high-level synthesis tool that produces dynamically scheduled circuits from C/C++ code. She is a recipient of the EDAA Outstanding Dissertation Award, Google Ph.D. Fellowship in Systems and Networking, Google Women Techmakers Scholarship, and Best Paper Award at FPGA'20.</p></section><footer class=article-footer></footer></article><footer class=site-footer><section class=copyright>&copy;
2022 -
2023 Open Neuromorphic</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.16.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>